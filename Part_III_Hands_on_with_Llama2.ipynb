{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HansHenseler/DFRWS-APAC-LLM-Workshop/blob/main/Part_III_Hands_on_with_Llama2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Part III: Hands on with Llama2\n",
        "\n",
        "This is an example for Instruction Answering and Chat Conversation. In the instruction answering you give an instruction to the LLM and the LLM makes the responses (Stage 3). In the chat conversation the LLM remembers previous prompts and answers (Stage 4).\n",
        "\n",
        "```\n",
        "This notebook is part of the DFRWS APAC 2023 workshop \"LLMs: Prompt Engineering and Retrieval Augmented Generation for Digital Forensics\" by\n",
        "\n",
        "Hans Henseler, University of Applied Sciences Leiden and Netherlands Forensic Institute, Netherlands\n",
        "Kwok-Yan Lam, Nanyang Technological University, Singapore\n",
        "and Zee Kin Yeong, Singapore Academy of Law, Singapore\n",
        "Victor C.W. Cheng, TAU Express Pte Ltd, Singapore\n",
        "\n",
        "Fore more information see: https://dfrws.org/presentation/llms-prompt-engineering-and-retrieval-augmented-generation/```\n",
        "\n",
        "Model used: llama-2-13b-chat.Q4_0.gguf\n",
        "Model: Llama 2,\n",
        "Size: 13B,\n",
        "Model type: Chat model\n",
        "Quantization: 4bit, native method\n",
        "Model Format: gguf\n",
        "\n",
        "First step: GET A GPU !!!\n"
      ],
      "metadata": {
        "id": "QVECpMJqLvGC"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage 1: Then install langchain and llama-cpp-python"
      ],
      "metadata": {
        "id": "npMLUhM-Lnj7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qG1tp3oxL4qg",
        "outputId": "d8f4f8ae-9ff1-44d5-b30d-c768e5551140"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.0.314)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.21)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.8.6)\n",
            "Requirement already satisfied: anyio<4.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.7.1)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.33)\n",
            "Requirement already satisfied: langsmith<0.1.0,>=0.0.43 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.43)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.23.5)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.10.13)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (3.3.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.4)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4.0->langchain) (1.1.3)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.20.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain) (2.4)\n",
            "Requirement already satisfied: typing-extensions>=4.2.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.5.0)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.6)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2023.7.22)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.0)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7,>=0.5.7->langchain) (23.2)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Install Llamma cpp python"
      ],
      "metadata": {
        "id": "ZO6hgFLsLqbb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!export LLAMA_CUBLAS=1\n",
        "!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip install llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HJ4UuiVqMuXz",
        "outputId": "8372b51c-011e-4e78-b697-3f5801be587c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: llama-cpp-python in /usr/local/lib/python3.10/dist-packages (0.2.11)\n",
            "Requirement already satisfied: typing-extensions>=4.5.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (4.5.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (1.23.5)\n",
            "Requirement already satisfied: diskcache>=5.6.1 in /usr/local/lib/python3.10/dist-packages (from llama-cpp-python) (5.6.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage 2: Get the Llama 2 13B chat model"
      ],
      "metadata": {
        "id": "FTxnea1fkNfw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# This is the chat model!\n",
        "!wget https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q4_0.gguf"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj7-_-1SP3QQ",
        "outputId": "b5ab6126-f846-4c54-ada6-aa28da0bfe4a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-10-16 07:10:59--  https://huggingface.co/TheBloke/Llama-2-13B-chat-GGUF/resolve/main/llama-2-13b-chat.Q4_0.gguf\n",
            "Resolving huggingface.co (huggingface.co)... 13.33.33.110, 13.33.33.102, 13.33.33.55, ...\n",
            "Connecting to huggingface.co (huggingface.co)|13.33.33.110|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://cdn-lfs.huggingface.co/repos/8d/b1/8db1d1f73b4caa58e947ccbfe2fb27ac5e495c2ad8457ad299d15987aee3b520/eda2a15d532bea4ce6fc14d15c2b72638243396816252f73a94dceeb0429112f?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27llama-2-13b-chat.Q4_0.gguf%3B+filename%3D%22llama-2-13b-chat.Q4_0.gguf%22%3B&Expires=1697699459&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NzY5OTQ1OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84ZC9iMS84ZGIxZDFmNzNiNGNhYTU4ZTk0N2NjYmZlMmZiMjdhYzVlNDk1YzJhZDg0NTdhZDI5OWQxNTk4N2FlZTNiNTIwL2VkYTJhMTVkNTMyYmVhNGNlNmZjMTRkMTVjMmI3MjYzODI0MzM5NjgxNjI1MmY3M2E5NGRjZWViMDQyOTExMmY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=A6SlieK3UMdeT20XDd-PGIAeVIlUY9s-cthwTRhqDm77w33m-mPktV3%7EtskH2g%7E0LViKk8vu52OfvSUag7CZFUrZx%7EuNHIuJdX5v86NFiOZk14KCLdGsktu-tFPhInDSP2mFXwx5hCUwg8mBbDF51vJDxisKyCGC6ntku9g8tYxQ0leFwQNSM4mqbi-BdWLVBQaDs50vQ3DwAk3eaQ7Ij9yBn10ozReAHtAd5LeoSFbb4TJPW02rv6wH%7Ev67wTkYZUHKNAWI9ovRpg18ALneHXiCE9X3Jz5UC-zERRBqdyxojgl%7E1Q-Op5iIOeUkcC1%7ECii8S5aEAgGcaAzslgkphw__&Key-Pair-Id=KVTP0A1DKRTAX [following]\n",
            "--2023-10-16 07:10:59--  https://cdn-lfs.huggingface.co/repos/8d/b1/8db1d1f73b4caa58e947ccbfe2fb27ac5e495c2ad8457ad299d15987aee3b520/eda2a15d532bea4ce6fc14d15c2b72638243396816252f73a94dceeb0429112f?response-content-disposition=attachment%3B+filename*%3DUTF-8%27%27llama-2-13b-chat.Q4_0.gguf%3B+filename%3D%22llama-2-13b-chat.Q4_0.gguf%22%3B&Expires=1697699459&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTY5NzY5OTQ1OX19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy5odWdnaW5nZmFjZS5jby9yZXBvcy84ZC9iMS84ZGIxZDFmNzNiNGNhYTU4ZTk0N2NjYmZlMmZiMjdhYzVlNDk1YzJhZDg0NTdhZDI5OWQxNTk4N2FlZTNiNTIwL2VkYTJhMTVkNTMyYmVhNGNlNmZjMTRkMTVjMmI3MjYzODI0MzM5NjgxNjI1MmY3M2E5NGRjZWViMDQyOTExMmY%7EcmVzcG9uc2UtY29udGVudC1kaXNwb3NpdGlvbj0qIn1dfQ__&Signature=A6SlieK3UMdeT20XDd-PGIAeVIlUY9s-cthwTRhqDm77w33m-mPktV3%7EtskH2g%7E0LViKk8vu52OfvSUag7CZFUrZx%7EuNHIuJdX5v86NFiOZk14KCLdGsktu-tFPhInDSP2mFXwx5hCUwg8mBbDF51vJDxisKyCGC6ntku9g8tYxQ0leFwQNSM4mqbi-BdWLVBQaDs50vQ3DwAk3eaQ7Ij9yBn10ozReAHtAd5LeoSFbb4TJPW02rv6wH%7Ev67wTkYZUHKNAWI9ovRpg18ALneHXiCE9X3Jz5UC-zERRBqdyxojgl%7E1Q-Op5iIOeUkcC1%7ECii8S5aEAgGcaAzslgkphw__&Key-Pair-Id=KVTP0A1DKRTAX\n",
            "Resolving cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)... 18.155.68.98, 18.155.68.128, 18.155.68.73, ...\n",
            "Connecting to cdn-lfs.huggingface.co (cdn-lfs.huggingface.co)|18.155.68.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7365834624 (6.9G) [binary/octet-stream]\n",
            "Saving to: ‘llama-2-13b-chat.Q4_0.gguf’\n",
            "\n",
            "llama-2-13b-chat.Q4 100%[===================>]   6.86G  16.1MB/s    in 7m 45s  \n",
            "\n",
            "2023-10-16 07:18:45 (15.1 MB/s) - ‘llama-2-13b-chat.Q4_0.gguf’ saved [7365834624/7365834624]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import LlamaCpp\n",
        "# Make sure the model path is correct for your system!\n",
        "llm = LlamaCpp(\n",
        "    model_path=\"/content/llama-2-13b-chat.Q4_0.gguf\", # location of the model\n",
        "    temperature=0.75,                 # temperature\n",
        "    max_tokens=2000,                 # Max. number of tokens to be generated\n",
        "    top_p=0.9,                    # top_p = 0.9\n",
        "    top_k=30,                     # top_k = 30\n",
        "    n_gpu_layers=43,                 # number of layers to offload to GPU\n",
        "    verbose=True, # Verbose is required to pass to the callback manager\n",
        "    n_batch=200,          # number of token generation in parallel\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k0APaGROMRMC",
        "outputId": "615618ec-8640-45d3-ca5d-b53b8cc87a5e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's check what GPU we have:\n",
        "\n",
        "```\n",
        "Mon Oct 16 04:18:30 2023       \n",
        "+-----------------------------------------------------------------------------+\n",
        "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
        "|-------------------------------+----------------------+----------------------+\n",
        "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
        "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
        "|                               |                      |               MIG M. |\n",
        "|===============================+======================+======================|\n",
        "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
        "| N/A   54C    P0    27W /  70W |   7949MiB / 15360MiB |      0%      Default |\n",
        "|                               |                      |                  N/A |\n",
        "+-------------------------------+----------------------+----------------------+\n",
        "                                                                               \n",
        "+-----------------------------------------------------------------------------+\n",
        "| Processes:                                                                  |\n",
        "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
        "|        ID   ID                                                   Usage      |\n",
        "|=============================================================================|\n",
        "+-----------------------------------------------------------------------------+\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "RbjUWezcT_y5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi"
      ],
      "metadata": {
        "id": "8PNez0eOP08R",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "972435be-aae2-4f97-dbed-bda60bbcd312"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mon Oct 16 07:08:35 2023       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 525.105.17   Driver Version: 525.105.17   CUDA Version: 12.0     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   42C    P8     9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage 3: Try the model with Instruction Answering"
      ],
      "metadata": {
        "id": "g6oL_Hj9kV3N"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"what is water?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 213
        },
        "id": "ScRdcYAQ72XM",
        "outputId": "82b3d750-cd83-4a1a-a110-8f7f4e46e183"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"\\nWater is a clear, colorless liquid that is essential for all known forms of life. It is the most abundant substance on Earth and covers about 71% of the planet's surface. Water is composed of hydrogen and oxygen atoms, with two hydrogen atoms bonded to one oxygen atom.\\n\\nThe physical properties of water are unique and critical for its role in supporting life. Some of these properties include:\\n\\n1. High specific heat capacity: Water has a high specific heat capacity, meaning it can absorb and release a lot of heat energy without a large change in temperature. This helps regulate the Earth's climate and maintain a relatively stable environment.\\n2. High thermal conductivity: Water is an excellent conductor of heat, which allows it to transfer heat energy efficiently. This property is essential for the regulation of ocean currents and the formation of weather patterns.\\n3. Density: Water is denser than most other substances, which helps it sink and flow downhill. This property is critical for the formation of rivers, lakes, and oceans.\\n4. Viscosity: Water has a moderate viscosity, which means it can flow easily but still retains its shape. This property is important for the proper functioning of living organisms, as it allows water to penetrate cells and transport nutrients and waste products.\\n5. Solubility: Water is an excellent solvent, capable of dissolving a wide range of substances. This property is essential for the formation of solutions that support life, such as sugars, salts, and other nutrients.\\n6. pH stability: Water has a stable pH level, ranging from 6.5 to 8.5, which is important for supporting the diversity of life on Earth.\\n7. Surface tension: Water has a high surface tension, which allows it to form droplets and hold its shape against gravity. This property is essential for the formation of lakes, rivers, and oceans.\\n\\nIn addition to these physical properties, water also has a number of chemical properties that are important for life. For example, water is a good solvent for many chemical reactions, and it can act as both an acid and a base in certain situations.\\n\\nOverall, the unique combination of physical and chemical properties found in water makes it\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"plan a 2 days trip in Singapore\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        },
        "id": "j-0xjdaf9kCk",
        "outputId": "e62eb1cb-3e17-412e-f861-5fdb314d54e3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\", what are the top things to do?\\n\\nAnswer:\\n\\nIf you're planning a two-day trip to Singapore, here are some top things to do to make the most of your visit:\\n\\nDay 1:\\n\\n1. Gardens by the Bay - Start your day with a visit to this iconic attraction. Take a stroll through the Flower Dome and Cloud Forest cooled conservatories, and enjoy the breathtaking views of the Supertree Grove.\\n2. Marina Bay Sands SkyPark - Head over to the rooftop garden of the Marina Bay Sands hotel for panoramic views of the city skyline. You can also take a walk along the promenade and enjoy the light and water show at night.\\n3. Merlion Park - Visit this famous landmark and take photos with the iconic half-lion, half-fish statue. You can also enjoy the nearby Singapore River and take a boat ride to see the city from a different perspective.\\n4. Chinatown - Explore the vibrant streets of Chinatown and experience its rich history and culture. Visit the Buddha Tooth Relic Temple, Chinatown Heritage Centre, and take a stroll along Pagoda Street for souvenir shopping.\\n5. Clarke Quay - Head over to this popular nightlife district and enjoy a meal at one of the many restaurants along the river. You can also take a boat ride or simply relax and people-watch.\\n\\nDay 2:\\n\\n1. Sentosa Island - Take a trip to this resort island and enjoy its beautiful beaches, water sports, and family-friendly attractions. Must-visit spots include Universal Studios Singapore, S.E.A. Aquarium, and Adventure Cove Waterpark.\\n2. Little India - Experience the vibrant Indian culture in this charming neighborhood. Visit the Sri Veeramakaliamman Temple, explore the colorful streets, and indulge in delicious Indian cuisine.\\n3. Haw Par Villa - End your trip with a visit to this unique theme park featuring Chinese mythology-themed attractions and giant dragon sculptures.\\n4. Lau Pa Sat - Have a final meal at this historic market turned food court, offering\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "txt = '''\n",
        "1. Gardens by the Bay - I want to see the Supertree Grove and the Flower Dome and Cloud Forest Domes.\n",
        "2. Marina Bay Sands - I want to take a photo with the iconic hotel and enjoy the light and water show at night.\n",
        "3. Merlion - I want to see the famous statue and take a photo with it.\n",
        "4. Singapore Flyer - I want to ride the giant Ferris wheel and enjoy the panoramic view of the city.\n",
        "5. Chinatown - I would like to explore the colorful streets and try some delicious street food.\n",
        "6. Little India - I would like to experience the vibrant Indian culture and try some authentic Indian cuisine.\n",
        "7. Haw Par Villa - I want to see the largest theme park in Singapore and enjoy the Chinese mythology-themed rides and attractions.\n",
        "8. Clarke Quay - I would like to visit the nightlife district and enjoy the bars, clubs, and live music performances.\n",
        "'''\n",
        "llm(\"Please summarize the following passage in 50 words. Passage: \" + txt)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "id": "PolJagGH-sYt",
        "outputId": "c694439a-6dd4-4dae-a534-095920bedcd2"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'9. Orchard Road - I want to go shopping at the famous shopping street and explore the various malls and department stores.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "llm(\"which countries are located in Europe\")"
      ],
      "metadata": {
        "id": "Vo8muDZAr17k",
        "outputId": "ed67f0c5-db86-4450-df3c-6c5a77cff5e4",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 230
        }
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"?\\n\\nThere are 50 countries located in Europe, and they are:\\n\\n1. Albania\\n2. Andorra\\n3. Armenia\\n4. Austria\\n5. Azerbaijan\\n6. Belarus\\n7. Belgium\\n8. Bosnia and Herzegovina\\n9. Bulgaria\\n10. Croatia\\n11. Cyprus\\n12. Czech Republic\\n13. Denmark\\n14. Estonia\\n15. Faroe Islands\\n16. Finland\\n17. France\\n18. Georgia\\n19. Germany\\n20. Gibraltar\\n21. Greece\\n22. Hungary\\n23. Iceland\\n24. Ireland\\n25. Italy\\n26. Kazakhstan\\n27. Kosovo\\n28. Latvia\\n29. Liechtenstein\\n30. Lithuania\\n31. Luxembourg\\n32. Malta\\n33. Moldova\\n34. Monaco\\n35. Montenegro\\n36. Netherlands\\n37. Norway\\n38. Poland\\n39. Portugal\\n40. Romania\\n41. Russia (partially)\\n42. San Marino\\n43. Serbia\\n44. Slovakia\\n45. Slovenia\\n46. Spain\\n47. Sweden\\n48. Switzerland\\n49. Turkey (partially)\\n50. Ukraine\\n\\nNote that some countries have territories located outside of Europe, such as Russia's Kaliningrad Oblast and Turkey's Istanbul province. Additionally, some countries have disputed borders or territorial claims, so this list may not be exhaustive or definitive.\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Stage 4: Try the model with Chat Conversation\n"
      ],
      "metadata": {
        "id": "IU3vwDtwYfYt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.llms import LlamaCpp\n",
        "model_path = \"/content/llama-2-13b-chat.Q4_0.gguf\"\n",
        "llm = LlamaCpp(model_path=model_path,\n",
        "               # n_ctx=4096,\n",
        "               seed=0,\n",
        "               temperature=0.1,\n",
        "               top_k=30,  # original 50\n",
        "               top_p=0.75,# original 0.95\n",
        "               n_batch=300,      # num. of parallel generation\n",
        "               n_gpu_layers=43,  # important for GPU\n",
        "               n_threads = 10,   # important for CPU\n",
        "               max_tokens=1024,\n",
        "               repeat_penalty=1.18,\n",
        "               )\n",
        "\n",
        "history = []\n",
        "\n",
        "def convert_message_and_history_to_llama2_chat_format(message: str, memory_limit = 7) -> str:\n",
        "    # memory_limit set to 7 -> only memorize latest 7 pairs of \"user, assistant\" conversation\n",
        "    global history\n",
        "\n",
        "    SYSTEM_PROMPT = \"\"\"<s>[INST] <<SYS>>\n",
        "    You are a helpful bot. Your answers are clear and concise.\n",
        "    <</SYS>>\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    if len(history) > memory_limit:\n",
        "        history = history[-memory_limit:]\n",
        "\n",
        "    if len(history) == 0:\n",
        "        return SYSTEM_PROMPT + f\"{message} [/INST]\"\n",
        "\n",
        "    # first message pair is treated differently\n",
        "    llama2_history_formated_message = SYSTEM_PROMPT + f\"user{history[0][0]} [/INST] {history[0][1]} </s>\"\n",
        "    # for 2nd and further message pairs\n",
        "    for user_msg, assistant_msg in history[1:]:\n",
        "        llama2_history_formated_message += f\"<s>[INST] {user_msg} [/INST] {assistant_msg} </s>\"\n",
        "    # for the current user message\n",
        "    llama2_history_formated_message += f\"<s>[INST] {message} [/INST]\"\n",
        "\n",
        "    return llama2_history_formated_message\n",
        "\n",
        "\n",
        "def generate_response(message: str) -> str:\n",
        "    global history\n",
        "\n",
        "    query = convert_message_and_history_to_llama2_chat_format(message)\n",
        "    responses = llm(query)\n",
        "    history.append((message, responses))\n",
        "    print(\"user: \", message)\n",
        "    print(\"assistant: \", responses)\n",
        "    print('\\n')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b63RFQhYYk35",
        "outputId": "a00a33b2-4cce-45eb-a806-9c0b3b6ffe03"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 1 | SSE3 = 1 | SSSE3 = 1 | VSX = 0 | \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "generate_response(\"hi\")\n",
        "generate_response(\"what is iron?\")\n",
        "generate_response(\"what is the boiling point of it?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-uW-HEjSbEWJ",
        "outputId": "67775de5-01c2-4fe6-e1d7-215d5817a001"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user:  hi\n",
            "assistant:    Hello! I'm here to help answer any questions you may have. What can I assist you with today?\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user:  what is iron?\n",
            "assistant:    Iron is a chemical element with the symbol Fe and atomic number 26. It is a metal that belongs to the group of transition metals and is one of the most common elements on Earth.\n",
            "\n",
            "Iron is an essential nutrient for many living organisms, including humans, where it plays a crucial role in the functioning of red blood cells and the transportation of oxygen throughout the body. It is also a key component in the synthesis of hemoglobin, which is the protein in red blood cells that carries oxygen.\n",
            "\n",
            "In addition to its biological importance, iron is also a critical material in many industrial processes, such as the production of steel, which is an alloy of iron and carbon. Steel is a key component in construction, transportation, and other industries, and it is estimated that over 90% of all metal produced worldwide is steel.\n",
            "\n",
            "Iron is also a significant component in the Earth's core, where it is thought to make up about 85% of the planet's total iron content. It is believed that the Earth's core is composed primarily of iron and nickel, with smaller amounts of lighter elements such as oxygen, silicon, and sulfur.\n",
            "\n",
            "Overall, iron is a versatile element that plays a vital role in many aspects of our lives, from the functioning of living organisms to the production of industrial materials.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Llama.generate: prefix-match hit\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "user:  what is the boiling point of it?\n",
            "assistant:    The boiling point of iron is approximately 2860°C (5176°F) at standard atmospheric pressure. This means that iron melts at a temperature of around 1538°C (2800°F) and boils at a temperature of around 2860°C (5176°F). However, it's important to note that the exact boiling point of iron can vary depending on the specific conditions in which it is being he\n",
            "\n",
            "\n"
          ]
        }
      ]
    }
  ]
}